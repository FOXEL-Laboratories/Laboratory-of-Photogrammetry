\documentclass[a4paper, 10pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{bbm}
\usepackage{lscape}
\usepackage{inputenc}
\usepackage{lmodern}
\usepackage{url}
\usepackage{float, graphicx}
\usepackage[sectionbib]{chapterbib}
\usepackage{hyperref}
\hypersetup{colorlinks=false, hidelinks}

\author{ St\'ephane Flotron, Pierre Moulon }
\title{\textbf{A new Global Pipeline solving the non-central camera SfM}}

\renewcommand{\tilde}{\widetilde}
\renewcommand{\t}{\mathbf{t}}
\renewcommand{\d}{\mathbf{d}}
\renewcommand{\b}{\mathbf{b}}
\newcommand{\m}{\mathbf{m}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\I}{\mathbb{I}}

\begin{document}
   \maketitle
   
   \section{ Preambule }
   
   \subsection{On the Plücker line representation}
   
   Let $L$ be a line of the 3D space $\R^3$ defined by the point $\x$ and $\y$. Let us now define $\d$ as 
   \begin{equation*}
       \d = \y-\x.
   \end{equation*}
   Then, The Cartesian representation of the line $L$ is 
   \begin{equation*}
       L : \x + \alpha \d, \ \alpha \in \R.
   \end{equation*}
   This representation of the line does not allow the use of homogeneous coordinates. Hence, a solution is to use Plücker
   line representation of $L$, $L : (\d,\m)$, where $\d$ and $\m$ are two vectors of $\R^3$ defined as :
   \begin{equation}
        \label{dandm}
       \d = \y-\x \mbox{ and } \m = (\x-\0) \wedge (\y-\0),
   \end{equation}
   where $\0$ is the origin of $\R^3$.
   
   \paragraph{}We are now interested us to intersection of lines represented in Plücker coordinate frame.
   Let $L_1 : (\d_1, \m_1)$ and $L_2 : (\d_2, \m_2)$ be two lines of $\R^3$ represented by Plücker
   line coordinates. $L_1$ intersect $L_2$ if and only if $L_1$ and $L_2$ are coplanar. In terms of Plücker 
   coordinates, this condition is the following :
   \begin{equation}
       \label{co-planarity condition}
       L_1 \cap L_2 \neq \emptyset \iff \d_1 \cdot \m_2 + \d_2 \cdot \m_1 = 0.
   \end{equation}

   \subsubsection*{Remark}
    In the case where $\x$ and $\y$ belongs to $\P^3$ (the projective space of dimension 3), the above definition of $\d$ and $\m$ does not hold anymore.
    Let us defined $p_{ij}$ as 
    \begin{equation*}
        p_{ij} = \left| 
             \begin{array}{cc}
                \x_i & y_i \\
                \x_j & y_j 
            \end{array}
        \right|.
    \end{equation*}
    Then $\d$ and $\m$ are defined as
    \begin{equation*}
           \d^T = (p_{01},\ p_{02},\ p_{03}) \mbox{ and } \m^T = (p_{23},\ p_{31},\ p_{12}). 
    \end{equation*}
    Taking $\x = (1, \x_1, \x_2, \x_3)$, $\y = (1, y_1, y_2, y_3)$ and using the above definition, 
    we recover $\d$ and $\m$ defined by relation \eqref{dandm}.
    
    \subsubsection{Rigid transformation of lines represented by Plücker coordinates}
    
    Let $\x$ and $\y$ be two vectors of $\R^3$ defining a line $L$. Here, we represent $L$ using Plücker line
    coordinates, $L : (m,d)$. We apply to $L$ the rigid transformation $f(\X) = R( \X-\t), \ \forall \X \in \R^3$, 
    where $R$ is a rotation matrix and $\t \in \R^3$. Denoting $L'=f(L)$ with Plücker coordinate $(\d', \m')$, 
    how are $\d'$ and $\m'$ related to $\m$ and $\d$ ? Using the definition \eqref{dandm} of $\d$ and $\m$, we have
    \begin{eqnarray*}
         \d' & = & f(\y) - f(\x) \\
             & = & R(\y-\t) -R(\x-\t) \\
             & = & R\y - R\x \\
             & = & R(\y-\x) \\
             & = & R\d.
    \end{eqnarray*}
    Similary, we have
    \begin{eqnarray*}
        \m' & = & f(\x) \wedge f(\y) \\
            & = & R(\x-\t) \wedge R(\y-\t) \\
            & = & R \x \wedge R\y - R\t \wedge R \y - R\x \wedge R \t \\
            & = & R( \x \wedge \y) - R\t \wedge R(\y-\x) \\
            & = & R( \x \wedge \y) - R( \t \wedge (\y -\x) \\
            & = & R \m - R ( \t \wedge \d ).
    \end{eqnarray*}
    Hence, for the rigid transformation $f$ defined by $f(\X) = R(\X-\t)$, we have
    \begin{equation}
       \label{plucker-transform}
        \d' = R\d \mbox{   and   } \m' = R\m - R ( \t \wedge \d ).
    \end{equation}
    The relation \eqref{plucker-transform} will be useful to derive the generalized epipolar constraint.
    
    \subsection{The generalized epipolar camera model}

    Let $L_1$ and $L_2$ be the rays related to the same 3D point seen by two cameras, respectively camera 1 and camera 2. We suppose that the Plücker line
    representation of $L_1$ and $L_2$ are known and denoted by
    \begin{equation*}
         L_1 : (\d_1, \m_1) \mbox{   and   } L_2 : (\d_2, \m_2 ).
    \end{equation*}
    We assume that $L_1$ is represented in camera 1 coordinate frame and that $L_2$ is represented in camera 2 coordinate frame.
    Without loss of generality, we can assume that camera 1 has pose $(\I_3 | \0)$ and that camera 2 has pose $(R, \t)$, where $R$ the orientation of
    the second camera with respect to the first and $\t$ the translation of second camera in camera 1 coordinate frame. 
    Denoting by $\X$ a point in camera one coordinate frame, it could be expressed in camera 2 coordinate frame by
    $$ \x_{cam}^2 = R\x_{cam}^1 + \t.$$
    Therefore, $\x_2^{cam}$ expressed in camera one coordinate frame is given by the following relation: 
    $
        \x_{cam}^1 = R^T( \x_{cam}^2 - \t). 
    $
    Hence, $L_2$ in camera one coordinate frame is given by :
    \begin{equation*}
        L^2 : (R^T \d_2, R^T \m_2 - R^T (\t \wedge \d_2).
    \end{equation*}
    Since $L_1$ and $L_2$ are seeing the same 3D point $\X$, the lines must intersect. From condition \eqref{co-planarity condition}, we have
    \begin{equation*}
        \d_1^T R^T \m_2 - \d_1^T R^T (\t \wedge \d_2 ) + \m_1^T R^T \d_2 = 0,  
    \end{equation*}
    which is equivalent to 
    \begin{equation}
        \label{ray intersection}
        \m_2^T R \d_1 + \d_2^T [\t]_{\times} R \d_1 + \d_2^T R \m_1 = 0.
    \end{equation}
    Writing equation \eqref{ray intersection} into a matrix product, we obtain the following expression
    \begin{equation}
        \label{generalized epipolar}
        (\d_2^T\ \m_2^T ) \left[ 
          \begin{array}{cc}
              [\t]_{\times} R & R \\
              R & \0 
          \end{array}
           \right] 
           \left( 
               \begin{array}{c}
                   \d_1 \\
                   \m_1
               \end{array}
           \right)
           = 0
    \end{equation}
    which the generalized epipolar condition. Let us remark that if we consider central camera, the momentums $\m_1$ and $\m_2$
    are equal to $\0$ because the rays passes through the origin. Then relation \eqref{generalized epipolar} reduces to
    $$ \d_2^T [\t]_{\times} R \d_1 = 0$$
    which is nothing else than the classical epipolar condition. Therefore \eqref{generalized epipolar} is
    a generalization of the epipolar condition.
    
   \section{Relative Rotation Estimation}

    
   \section{Relative translation Estimation}
   
   During this section, we assume that the rotation $R_i$ of each pose $i$ is known. The aim of this section is to develop
   a numerical scheme in order to estimation the relative translations $\t_{ij}$ between two poses. Once the are known, 
   the relative translations could be merged using the approach of \cite{moulon-tel-00996935} in order to retrieve the global translations.
   
   \subsection{Parametric model (reduced trifocal tensor)} 
   We assume here that the tracks between the poses are know, i.e that correspondences between the sub cameras
   of the camera rigs are known. The tracks are assumed to be of length at least 3, so that the corresponding 3D point is
   seem from at least three poses. The method presented hereafter is based on the one developed by Pierre Moulon
   (see \cite{moulon-tel-00996935} chapter 6, section 6.2.3, p.129 for the original method). Following \cite{moulon-tel-00996935}, 
   we define the interpose similarity measure as the re-projection error defined by 
    \begin{equation}
        \label{similarity}
        \begin{aligned}
        & \rho(\t_i, \X_j) && = \left \| \left (
                              \x_j^{c,i}(1) - \frac{(R_c R_i \X_j + R_c \t_i + \t_c)^1}{(R_c R_i \X_j + R_c \t_i + \t_c)^3}, \right. \right. \\
                           &&& \qquad \qquad \qquad  \left. \left. \x_j^{c,i}(2) - \frac{(R_c R_i \X_j + R_c \t_i + \t_c)^2}{(R_c R_i \X_j + R_c \t_i + \t_c)^3}
                          \right) \right\|_\infty
        \end{aligned}
    \end{equation}
    where
    \begin{itemize}
        \item[$\x_j^{c,i}$] is the pixel of sub-camera $c$ of pose $i$ corresponding to the 3D point $\X_j$ 
        \item[$\X_j$] is a 3D point,
        \item[$R_c$] is the relative orientation of the sub-camera $c$ in the camera rig referential frame,
        \item[$R_i$] is the orientation of pose $i$,
        \item[$\t_i$] is the translation of pose $i$,
        \item[$\t_c$] is the translation of sub-camera $c$ in the camera rig referential frame.
    \end{itemize}
   
   Le be $(I,J,K)$ a triplet of poses such that the composition of the relative rotation is the 
   identity matrix, i.e.
   $$ R_{IJ} R_{JK} R_{KI} = I_3.$$ 
   where $R_{ij}$ is the relative orientation of rig $j$ in the pose $i$. 
   The problem we want to solve in order to estimate the relative translation
   $\t_1 = \mathbf{0}, \t_2= \t_{IJ}, \t_3 = \t_{IK}$ between the poses $I, J$ and $K$ is 
   \begin{equation}
       \label{parametric model}
       \begin{aligned}
           \underset{\{\t_i\}_i, \{\X_j\}_j}{\mbox{minimize}}  && \quad  & \gamma &&& \\
           &&&&&\\
           \mbox{such that} && \ & \rho(\t_i, \X_j) \leq \gamma && \forall i, j \in \{1,2,3,4\} \\
            & && (R_c R_i \X_j + R_c \t_i + \t_c)^3 \geq 1 & \ & \forall i,j \\
            &&& \t_1 = (0,0,0) &&
       \end{aligned}
   \end{equation}
   Only 4 3D-points are needed to estimate the relative translations between the three poses. 
   The model would be estimated using AC-RANSAC with an upper bound threshold of $\gamma=2.0$ pixels. For more information
   about the mathematical basis of the model, we refer us to \cite{moulon-tel-00996935}.
   
   \subsubsection*{Note}
   Denoting by $R^k$ the $k$-th row of the matrix $R$, The constraint $\rho(\t_i, \X_j) \leq \gamma$ is equivalent to 
   \begin{equation*}
     \left\{
         \begin{aligned}
            & \X_j\left[ (R_cR_i)^k + (\gamma-\x_j^{c,i}(k)) (R_cR_i)^3 \right] + \left[R_c^3(\gamma-\x_j^{c,i}(k))+R_c^k\right]\t_i  \\
            & \qquad \qquad + [\t_c^k + (\gamma-\x_j^{c,i}(k))\t_c^3] \geq 0 \\
            & \X_j\left[ (R_cR_i)^k - (\gamma + \x_j^{c,i}(k)) (R_cR_i)^3 \right] + \left[-R_c^3(\gamma+\x_j^{c,i}(k))+R_c^k\right]\t_i  \\
            & \qquad \qquad + [\t_c^k - (\gamma+\x_j^{c,i}(k))\t_c^3] \leq 0 \\
         \end{aligned}
       \right\}, \\ \forall k \in {1,2}.
   \end{equation*}
   Because $R_c$ et $\t_c$ are known from calibration, the previous problem is linear in $\X_j$ and $\t_i$.
   
   \subsection{3D points distance minimization}
   The previous formulation seems quite fine, but from the representation of the re-projection error, we
   are still in a central camera case with three cameras, even if we consider the sub-poses in the formulation
   of model \eqref{parametric model}.
   
   \paragraph{} In order to avoid this problem, we present now a model in which we are 
   in a global referential frame, which seems more suitable for the representation of the scene with non 
   central cameras. Let $\X$ be a 3D point seen from camera $c$ with sub-pose ($R_c, C_c$) in a camera
   rig of pose $(R_r, C_r)$. Moreover, let us denote the corresponding bearing vector as $\b$. Then the relation
   between $\b$ and $\X$ is
   \begin{equation*}
      \alpha \b = R_c R_r \X + R_c \t_r + \t_c 
   \end{equation*}
   where $\alpha$ is the depth of the point $\X$ in the camera $c$ referential frame, $\t_c = -R_c C_c$ and $\t_r = -R_r C_r$. 
   Inverting the previous relation leads to the following equation 
   \begin{equation*}
       \X = \alpha R_r^T R_c^T  \b + R_r^T C_c + C_r.
   \end{equation*}
   Let $\X_l$, $l \in \mathbb{N}$ a 3D points issued from pose $i$ and sub-camera $k$. Then 
   \begin{equation*}
      \X_l = \alpha_l^i R_i^T R_k^T  \b_l + R_i^T C_{k} + C_i
   \end{equation*}
   and if $\X_l$ is seen from two poses $i$ and $j$, we have
   \begin{eqnarray*}
     \X_l & = & \X_{l, i} = \alpha_l^i R_i^T R_{k,i}^T  \b_{l, i} + R_i^T C_{k,i} + C_i \\
          & = & \X_{l, j} = \alpha_l^j R_j^T R_{k,j}^T  \b_{l, j} + R_j^T C_{k,j} + C_j.
   \end{eqnarray*}
   However, in practice, the bearing vectors $\b_{l,i}$ and $\b_{l,j}$ are noisy so that the above equality is never 
   fulfilled. Nevertheless, we can ensure that the distance between $\X_{l,i}$ and $\X_{l,j}$ is 
   less than a given threshold $\sigma$. In fact we would ensure that 
   \begin{equation*}
       \| \X_{l, i} -\X_{l, j} \|_{\infty} \leq \sigma.
   \end{equation*}
   Le be $(I,J,K)$ a triplet of poses such that the composition of the relative rotation is the 
   identity matrix, i.e.
   $$ R_{IJ} R_{JK} R_{KI} = I_3.$$ 
   where $R_{ij}$ is the relative orientation of rig $j$ in the pose $i$.
   We could now present the scheme based on distance minimization. We assume that for each of the three poses we know the bearings vectors 
   corresponding to a 3D points $\X_l$, $l=0,\dots,3$. In practice, this means that 4 tracks of length greater or equal 3 are known, and that the tracks
   are shared by the three poses $I, J$ and $K$. Knowing that, 
   we are looking for depths $\alpha_{l,i}$ and poses center that minimize the following problem:
   \begin{equation*}
       \begin{aligned}
          \underset{\{C_i\}_i, \{\alpha_l^i\}_{l,i}}{ \mbox{minimize}}  && \quad  & \sigma &&& \\
           &&&&&\\
           \mbox{such that} && \ & \| \X_{l,i} - \X_{l,j}\|_{\infty} \leq \sigma && \\
           &&& \forall l \in \{0,1,2,3\}, \forall i \neq j \in \{I,J,K\} \\
       \end{aligned}
   \end{equation*}
   However, in pratice, we need the relative translations, so we consider the following equivalent problem:
   \begin{equation}
       \label{distance translation model}
       \begin{aligned}
          \underset{\{\t_i\}_i, \{\alpha_l^i\}_{l,i}}{ \mbox{minimize}}  && \quad  & \sigma &&& \\
           &&&&&\\
           \mbox{such that} && \ & \| \overline {\X}_{l,i} - \overline {\X}_{l,j}\|_{\infty} \leq \sigma && \\
           &&& \forall l \in \{0,1,2,3\}, \forall i \neq j \in \{I,J,K\} \\
       \end{aligned}
   \end{equation}
   where 
   \begin{equation*}
       \overline{\X}_{l, i} = \alpha_l^i R_i^T R_{k,i}^T  \b_{l, i} + R_i^T C_{k,i} -R_i^T \t_i.
   \end{equation*}
   The model would be estimated using AC-RANSAC with an upper bound threshold $\sigma=0.01$ meters, because 
   we made the implicit assumption that the centers $C_k$ of the cameras of the rig structure are in meters.
   
   \subsubsection*{Remark}
   Denoting by $1_3$ the vector $(1,1,1)^T$, the equation $ \| \overline {\X}_{l,i} - \overline {\X}_{l,j}\|_{\infty} \leq \sigma $ could easily 
   be rewritten as 
   \begin{equation}
     \label{expanded distance}
     \begin{aligned}
       & -\sigma 1_3 -R_i^T C_{k,i} + R_j^T C_{k,j} & \leq & 
          \ \alpha_i^l R_i^T R_{k,i}^T \b_{l,i} - \alpha_j^l R_j^T R_{k,j}^T \b_{l,j}
             -R_i^T \t_i + R_j^T \t_j \\
       && \leq & \sigma 1_3 -R_i^T C_{k,i} + R_j^T C_{k,j}.
     \end{aligned}
   \end{equation}
   The equation \eqref{expanded distance} could be split into two inequalities which are easily implemented in linear programming solver such 
   as OSI-CLP.

   \section{Conclusions}
   
% ================================================================
%  Bibliography
% ================================================================

  \bibliography{biblio}
  \bibliographystyle{acm}
%  \bibliographystyle{plain}
   
\end{document}
